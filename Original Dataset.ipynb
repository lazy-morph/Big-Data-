{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    Positive = \"Positive\"\n",
    "    Negative = \"Negative\"\n",
    "    Neutral = \"Neutral\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.getSentiment()\n",
    "        \n",
    "    def getSentiment(self):\n",
    "        if (self.score <= 2):\n",
    "            return Sentiment.Negative\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.Neutral\n",
    "        else:\n",
    "            return Sentiment.Positive\n",
    "        \n",
    "\n",
    "f = spark.read.json('/home/shivam/intern/rev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73041, 72008, 71444, 69394, 70715, 73611, 73776, 67348]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.rdd.glom().map(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|overall| count|\n",
      "+-------+------+\n",
      "|    1.0| 16789|\n",
      "|    2.0| 19587|\n",
      "|    3.0| 45818|\n",
      "|    4.0|122647|\n",
      "|    5.0|366496|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f.groupBy(\"overall\").count().orderBy(\"overall\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = f.withColumn(\"overint\",f[\"overall\"].cast(\"Int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|overint|\n",
      "+-------+\n",
      "|      5|\n",
      "|      5|\n",
      "|      4|\n",
      "|      4|\n",
      "|      4|\n",
      "|      5|\n",
      "|      5|\n",
      "|      4|\n",
      "|      5|\n",
      "|      5|\n",
      "|      4|\n",
      "|      3|\n",
      "|      5|\n",
      "|      4|\n",
      "|      5|\n",
      "|      5|\n",
      "|      5|\n",
      "|      4|\n",
      "|      4|\n",
      "|      2|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.printSchema()\n",
    "\n",
    "df.select('overint').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select(\"overint\",\"reviewText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2.repartition(5,'overint')\n",
    "df2 = df2.coalesce(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|overint|          reviewText|\n",
      "+-------+--------------------+\n",
      "|      5|This came in on t...|\n",
      "|      5|I had a factory G...|\n",
      "|      4|If you don't have...|\n",
      "|      4|This works no bet...|\n",
      "|      4|I purchased this ...|\n",
      "|      5|Needed this tool ...|\n",
      "|      5|If u don't have i...|\n",
      "|      4|This light will n...|\n",
      "|      5|Light and laser t...|\n",
      "|      5|Does everything i...|\n",
      "|      4|Very bright.  I w...|\n",
      "|      3|It's cheaply made...|\n",
      "|      5|Mine arrived with...|\n",
      "|      4|It works great it...|\n",
      "|      5|I love this light...|\n",
      "|      5|Bit bulky. One bu...|\n",
      "|      5|it is bright and ...|\n",
      "|      4|A mice bright lig...|\n",
      "|      4|Had one ride on t...|\n",
      "|      2|So it worked well...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|overint| count|\n",
      "+-------+------+\n",
      "|      1| 16789|\n",
      "|      2| 19587|\n",
      "|      3| 45818|\n",
      "|      4|122647|\n",
      "|      5|366496|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy(\"overint\").count().orderBy(\"overint\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.mode(\"overwrite\").json(\"/home/shivam/intern/coal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73041, 143452, 69394, 144326, 141124]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.rdd.glom().map(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "part0 = \"/home/shivam/intern/coal/part-00004-d3495b0e-29c8-47d5-aef5-60a1b3fe5b06-c000.json\"\n",
    "\n",
    "reviews1 = []\n",
    "with open(part0) as p0:\n",
    "    for line in p0:\n",
    "        review = json.loads(line)\n",
    "        reviews1.append(Review(review['reviewText'],review['overint']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "part1 = \"/home/shivam/intern/repart/part-00001-06a43a4e-b6a6-45a0-a12d-0ee5869b345b-c000.json\"\n",
    "\n",
    "reviews2 = []\n",
    "with open(part1) as p1:\n",
    "    for line in p1:\n",
    "        review = json.loads(line)\n",
    "        reviews2.append(Review(review['reviewText'],review['overint']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "part2 = \"/home/shivam/intern/repart/part-00002-06a43a4e-b6a6-45a0-a12d-0ee5869b345b-c000.json\"\n",
    "\n",
    "reviews3 = []\n",
    "with open(part2) as p2:\n",
    "    for line in p2:\n",
    "        review = json.loads(line)\n",
    "        reviews3.append(Review(review['reviewText'],review['overint']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "part3 = \"/home/shivam/intern/repart/part-00003-06a43a4e-b6a6-45a0-a12d-0ee5869b345b-c000.json\"\n",
    "\n",
    "reviews4 = []\n",
    "with open(part3) as p3:\n",
    "    for line in p3:\n",
    "        review = json.loads(line)\n",
    "        reviews4.append(Review(review['reviewText'],review['overint']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "part4 = \"/home/shivam/intern/repart/part-00004-06a43a4e-b6a6-45a0-a12d-0ee5869b345b-c000.json\"\n",
    "\n",
    "reviews5 = []\n",
    "with open(part4) as p4:\n",
    "    for line in p4:\n",
    "        review = json.loads(line)\n",
    "        reviews5.append(Review(review['reviewText'],review['overint']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training,test = train_test_split(reviews1,test_size = 0.25,random_state = 40)\n",
    "\n",
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive' 'Positive' 'Positive' ... 'Positive' 'Positive' 'Positive']\n",
      "--- 78.44758582115173 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors,train_y)\n",
    "x = clf_dec.predict(test_x_vectors)\n",
    "print(x)\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#clf_lg = LogisticRegression()\n",
    "#clf_lg.fit(train_x_vectors,train_y)\n",
    "#clf_lg.predict(test_x_vectors)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
